[[AI]] and You: An Evaluation Of Autonomous Bias

Nick Pierce, Chase Staples, Matthew Berry

**Abstract:**

Advancements in technology have continuously redefine what is feasible in computing.  The expansion of computational power, coupled with the availability of complex data, have tandemly led to the creation of Artificial Intelligence (AI). [[AI]] has increasingly become more prominent within a plethora of applications such as proactive predictions, multifaceted data evaluation, as well as data mining.  Just as the prominence of [[AI]] and its capabilities continues to grow,  so too does the drawbacks associate with it. One such drawback is the bias within [[AI]].  The propensities of this concerning behavior have led to intense vetting and scrutiny into the creation of [[AI]] and the scopes/depth of when [[AI]] should be used. Various examples of artificial bias include the exclusion of or the enforcement of stereotypical prejudices/assumptions upon certain demographics\-- most commonly minority ones. [[AI]]'s ubiquity and potential amplifies the importance of uncovering the root factor/s of these complications. By studying the architectural composition of what "makes up" [[AI]], how instructional data is garnered and processed, and why current implementations of feedback loops tend to exacerbate bias patterns witnessed within artificial intelligence modifications can be instituted to mediate the underlying causes of these troubling trends.  This paper serves to provide an overview analysis of what [[AI]] is, how it is created, the relationship between [[AI]] creation and bias, and the strategies that are being procured to address the irregularities. 
